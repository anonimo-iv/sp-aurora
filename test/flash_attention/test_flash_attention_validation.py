#!/usr/bin/env python3
"""
Enhanced validation tests for Flash Attention implementation with Ring Attention
Tests numerical correctness, memory efficiency, and ring communication patterns
"""

import os
import sys
import torch
import torch.distributed as dist
import time
import traceback
from typing import Tuple, Optional
import math

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Check for Intel GPU support
try:
    import intel_extension_for_pytorch as ipex
    INTEL_GPU_AVAILABLE = torch.xpu.is_available() if hasattr(torch, 'xpu') else False
except ImportError:
    INTEL_GPU_AVAILABLE = False

# Import flash attention modules
from sp_aurora.intel_flash_attn import intel_flash_attn_forward, intel_flash_attn_backward
from sp_aurora.intel_sp_aurora import intel_sp_aurora_func


def compute_reference_attention(
    q: torch.Tensor,
    k: torch.Tensor,
    v: torch.Tensor,
    causal: bool = False,
    softmax_scale: Optional[float] = None
) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    Compute reference attention implementation with LSE
    """
    batch_size, num_heads, seq_len, head_dim = q.shape
    
    if softmax_scale is None:
        softmax_scale = 1.0 / math.sqrt(head_dim)
    
    # Compute attention scores
    scores = torch.matmul(q, k.transpose(-2, -1)) * softmax_scale
    
    # Apply causal mask if needed
    if causal:
        mask = torch.triu(torch.ones(seq_len, seq_len, device=scores.device), diagonal=1)
        scores = scores.masked_fill(mask.bool(), float('-inf'))
    
    # Compute LSE for numerical stability
    lse = torch.logsumexp(scores, dim=-1, keepdim=False)
    
    # Compute attention weights
    attn_weights = torch.exp(scores - lse.unsqueeze(-1))
    
    # Compute output
    output = torch.matmul(attn_weights, v)
    
    return output, lse


def test_numerical_precision():
    """Test numerical precision with stricter tolerances"""
    print("\n" + "="*60)
    print("TEST: Numerical Precision with Strict Tolerances")
    print("="*60)
    
    device = 'xpu' if INTEL_GPU_AVAILABLE else 'cuda' if torch.cuda.is_available() else 'cpu'
    dtype = torch.float32  # Use float32 for better precision testing
    
    # Test configurations with various sizes
    test_configs = [
        {"batch": 1, "seqlen": 64, "nheads": 4, "d": 32, "causal": True},
        {"batch": 2, "seqlen": 128, "nheads": 8, "d": 64, "causal": False},
        {"batch": 1, "seqlen": 256, "nheads": 12, "d": 64, "causal": True},
        {"batch": 4, "seqlen": 512, "nheads": 16, "d": 128, "causal": False},
    ]
    
    all_passed = True
    
    for i, config in enumerate(test_configs):
        print(f"\nConfig {i+1}: {config}")
        
        batch_size = config["batch"]
        seqlen = config["seqlen"]
        nheads = config["nheads"]
        d = config["d"]
        causal = config["causal"]
        
        # Create identical test tensors with controlled values
        torch.manual_seed(42)  # For reproducibility
        q = torch.randn(batch_size, nheads, seqlen, d, device=device, dtype=dtype)
        k = torch.randn(batch_size, nheads, seqlen, d, device=device, dtype=dtype)
        v = torch.randn(batch_size, nheads, seqlen, d, device=device, dtype=dtype)
        
        # Normalize inputs to prevent numerical overflow
        q = q / q.norm(dim=-1, keepdim=True)
        k = k / k.norm(dim=-1, keepdim=True)
        
        try:
            # Compute reference
            ref_out, ref_lse = compute_reference_attention(q, k, v, causal=causal)
            
            # Compute with Intel flash attention
            flash_out, flash_lse = intel_flash_attn_forward(q, k, v, causal=causal)
            
            # Convert to same dtype for comparison
            flash_out = flash_out.to(dtype)
            flash_lse = flash_lse.to(dtype)
            
            # Compute differences
            out_diff = (flash_out - ref_out).abs()
            lse_diff = (flash_lse - ref_lse).abs()
            
            max_out_diff = out_diff.max().item()
            mean_out_diff = out_diff.mean().item()
            max_lse_diff = lse_diff.max().item()
            mean_lse_diff = lse_diff.mean().item()
            
            print(f"Output - Max diff: {max_out_diff:.6e}, Mean diff: {mean_out_diff:.6e}")
            print(f"LSE    - Max diff: {max_lse_diff:.6e}, Mean diff: {mean_lse_diff:.6e}")
            
            # Strict tolerance checks
            out_rtol = 1e-3 if dtype == torch.float32 else 1e-2
            out_atol = 1e-5 if dtype == torch.float32 else 1e-3
            lse_rtol = 1e-3 if dtype == torch.float32 else 1e-2
            lse_atol = 1e-4 if dtype == torch.float32 else 1e-2
            
            out_match = torch.allclose(flash_out, ref_out, rtol=out_rtol, atol=out_atol)
            lse_match = torch.allclose(flash_lse, ref_lse, rtol=lse_rtol, atol=lse_atol)
            
            if out_match and lse_match:
                print("✅ Numerical precision test PASSED")
            else:
                print("❌ Numerical precision test FAILED")
                if not out_match:
                    print(f"   Output mismatch exceeds tolerance (rtol={out_rtol}, atol={out_atol})")
                if not lse_match:
                    print(f"   LSE mismatch exceeds tolerance (rtol={lse_rtol}, atol={lse_atol})")
                all_passed = False
                
        except Exception as e:
            print(f"❌ Test failed with error: {e}")
            traceback.print_exc()
            all_passed = False
    
    return all_passed


def test_memory_efficiency():
    """Test memory efficiency of flash attention vs standard attention"""
    print("\n" + "="*60)
    print("TEST: Memory Efficiency Analysis")
    print("="*60)
    
    if not (INTEL_GPU_AVAILABLE or torch.cuda.is_available()):
        print("⚠️  GPU not available, skipping memory efficiency test")
        return True
    
    device = 'xpu' if INTEL_GPU_AVAILABLE else 'cuda'
    dtype = torch.float16
    
    # Test configurations
    test_configs = [
        {"batch": 1, "seqlen": 1024, "nheads": 8, "d": 64},
        {"batch": 1, "seqlen": 2048, "nheads": 8, "d": 64},
        {"batch": 1, "seqlen": 4096, "nheads": 8, "d": 64},
    ]
    
    print("\nComparing memory usage: Flash Attention vs Standard Attention")
    print("-" * 60)
    
    for config in test_configs:
        batch_size = config["batch"]
        seqlen = config["seqlen"]
        nheads = config["nheads"]
        d = config["d"]
        
        print(f"\nSequence length: {seqlen}")
        
        # Create test tensors
        q = torch.randn(batch_size, nheads, seqlen, d, device=device, dtype=dtype)
        k = torch.randn(batch_size, nheads, seqlen, d, device=device, dtype=dtype)
        v = torch.randn(batch_size, nheads, seqlen, d, device=device, dtype=dtype)
        
        # Measure memory for standard attention
        if device == 'cuda':
            torch.cuda.reset_peak_memory_stats()
            torch.cuda.synchronize()
        elif device == 'xpu':
            if hasattr(torch.xpu, 'reset_peak_memory_stats'):
                torch.xpu.reset_peak_memory_stats()
            torch.xpu.synchronize()
        
        try:
            # Standard attention (will OOM for very long sequences)
            ref_out, ref_lse = compute_reference_attention(q, k, v, causal=True)
            
            if device == 'cuda':
                torch.cuda.synchronize()
                standard_memory = torch.cuda.max_memory_allocated() / 1e9
            elif device == 'xpu' and hasattr(torch.xpu, 'max_memory_allocated'):
                torch.xpu.synchronize()
                standard_memory = torch.xpu.max_memory_allocated() / 1e9
            else:
                standard_memory = 0
                
            print(f"Standard attention memory: {standard_memory:.3f} GB")
        except RuntimeError as e:
            if "out of memory" in str(e).lower():
                print("Standard attention: OOM")
                standard_memory = float('inf')
            else:
                raise
        
        # Clear memory
        if 'ref_out' in locals():
            del ref_out, ref_lse
        if device == 'cuda':
            torch.cuda.empty_cache()
        elif device == 'xpu' and hasattr(torch.xpu, 'empty_cache'):
            torch.xpu.empty_cache()
        
        # Measure memory for flash attention
        if device == 'cuda':
            torch.cuda.reset_peak_memory_stats()
            torch.cuda.synchronize()
        elif device == 'xpu':
            if hasattr(torch.xpu, 'reset_peak_memory_stats'):
                torch.xpu.reset_peak_memory_stats()
            torch.xpu.synchronize()
        
        # Flash attention
        flash_out, flash_lse = intel_flash_attn_forward(q, k, v, causal=True)
        
        if device == 'cuda':
            torch.cuda.synchronize()
            flash_memory = torch.cuda.max_memory_allocated() / 1e9
        elif device == 'xpu' and hasattr(torch.xpu, 'max_memory_allocated'):
            torch.xpu.synchronize()
            flash_memory = torch.xpu.max_memory_allocated() / 1e9
        else:
            flash_memory = 0
            
        print(f"Flash attention memory: {flash_memory:.3f} GB")
        
        if standard_memory != float('inf') and flash_memory > 0:
            reduction = (1 - flash_memory / standard_memory) * 100
            print(f"Memory reduction: {reduction:.1f}%")
            
            # Flash attention should use significantly less memory
            if reduction > 20:  # Expect at least 20% reduction
                print("✅ Memory efficiency test PASSED")
            else:
                print("⚠️  Memory reduction less than expected")
        else:
            print("✅ Flash attention succeeded where standard attention failed (OOM)")
    
    return True


def test_ring_communication_pattern():
    """Test the correctness of ring communication pattern"""
    print("\n" + "="*60)
    print("TEST: Ring Communication Pattern Correctness")
    print("="*60)
    
    if not dist.is_initialized():
        print("⚠️  Distributed not initialized, skipping ring communication test")
        print("   Run with: mpiexec -n 2 python test_flash_attention_validation.py")
        return True
    
    rank = dist.get_rank()
    world_size = dist.get_world_size()
    
    if world_size < 2:
        print("⚠️  Need at least 2 processes for ring communication test")
        return True
    
    device = 'xpu' if INTEL_GPU_AVAILABLE else 'cuda' if torch.cuda.is_available() else 'cpu'
    if device == 'xpu':
        device = f'xpu:{rank % torch.xpu.device_count()}'
    elif device == 'cuda':
        device = f'cuda:{rank % torch.cuda.device_count()}'
    
    dtype = torch.float16 if device != 'cpu' else torch.float32
    
    # Test configuration
    batch_size = 1
    seqlen_per_rank = 128
    nheads = 8
    d = 64
    
    print(f"[Rank {rank}] Testing ring pattern with {world_size} processes")
    
    # Create test data with rank-specific patterns
    torch.manual_seed(rank)
    q = torch.randn(batch_size, seqlen_per_rank, nheads, d, device=device, dtype=dtype) * (rank + 1)
    k = torch.randn(batch_size, seqlen_per_rank, nheads, d, device=device, dtype=dtype) * (rank + 1)
    v = torch.randn(batch_size, seqlen_per_rank, nheads, d, device=device, dtype=dtype) * (rank + 1)
    
    # Add markers to validate communication
    q[:, 0, 0, 0] = float(rank)  # Mark first element with rank
    k[:, 0, 0, 0] = float(rank * 10)
    v[:, 0, 0, 0] = float(rank * 100)
    
    try:
        # Run ring flash attention
        result = intel_sp_aurora_func(
            q, k, v, 
            causal=True,
            return_attn_probs=False
        )
        
        # Handle different return formats
        if isinstance(result, tuple):
            output = result[0]
            lse = result[1] if len(result) > 1 else None
        else:
            output = result
            lse = None
        
        print(f"[Rank {rank}] Ring attention completed successfully")
        print(f"[Rank {rank}] Output shape: {output.shape}")
        if lse is not None:
            print(f"[Rank {rank}] LSE shape: {lse.shape}")
        
        # Verify output properties
        assert not torch.isnan(output).any(), f"[Rank {rank}] Output contains NaN"
        assert not torch.isinf(output).any(), f"[Rank {rank}] Output contains Inf"
        if lse is not None:
            assert not torch.isnan(lse).any(), f"[Rank {rank}] LSE contains NaN"
            assert not torch.isinf(lse).any(), f"[Rank {rank}] LSE contains Inf"
        
        # Check that output is influenced by all ranks (not just local)
        # In proper ring attention, each rank's output should depend on all K,V
        output_mean = output.mean().item()
        print(f"[Rank {rank}] Output mean: {output_mean:.4f}")
        
        # Synchronize for collective validation
        dist.barrier()
        
        if rank == 0:
            print("\n✅ Ring communication pattern test PASSED")
            print("   All ranks completed successfully")
            
        return True
        
    except Exception as e:
        print(f"[Rank {rank}] ❌ Ring communication test failed: {e}")
        traceback.print_exc()
        return False


def test_gradient_correctness():
    """Test gradient computation correctness"""
    print("\n" + "="*60)
    print("TEST: Gradient Correctness")
    print("="*60)
    
    device = 'xpu' if INTEL_GPU_AVAILABLE else 'cuda' if torch.cuda.is_available() else 'cpu'
    dtype = torch.float32  # Use float32 for gradient checking
    
    batch_size = 1
    seqlen = 64
    nheads = 4
    d = 32
    
    # Create test tensors with gradients enabled
    q = torch.randn(batch_size, nheads, seqlen, d, device=device, dtype=dtype, requires_grad=True)
    k = torch.randn(batch_size, nheads, seqlen, d, device=device, dtype=dtype, requires_grad=True)
    v = torch.randn(batch_size, nheads, seqlen, d, device=device, dtype=dtype, requires_grad=True)
    
    # Forward pass
    output, lse = intel_flash_attn_forward(q, k, v, causal=True)
    
    # Create gradient for output
    grad_output = torch.randn_like(output)
    
    # Backward pass
    output.backward(grad_output)
    
    # Check that gradients exist and are finite
    for name, tensor in [("q", q), ("k", k), ("v", v)]:
        assert tensor.grad is not None, f"No gradient for {name}"
        assert torch.isfinite(tensor.grad).all(), f"Non-finite gradients in {name}"
        grad_norm = tensor.grad.norm().item()
        print(f"Gradient norm for {name}: {grad_norm:.4f}")
    
    # Numerical gradient check with finite differences
    print("\nPerforming numerical gradient check...")
    epsilon = 1e-4
    
    # Check gradient for a few random elements
    for _ in range(5):
        # Random position
        b = 0
        h = torch.randint(0, nheads, (1,)).item()
        s = torch.randint(0, seqlen, (1,)).item()
        d_idx = torch.randint(0, d, (1,)).item()
        
        # Finite difference for q
        q_orig = q.data[b, h, s, d_idx].item()
        
        # Forward direction
        q.data[b, h, s, d_idx] = q_orig + epsilon
        out_plus, _ = intel_flash_attn_forward(q, k, v, causal=True)
        loss_plus = (out_plus * grad_output).sum().item()
        
        # Backward direction
        q.data[b, h, s, d_idx] = q_orig - epsilon
        out_minus, _ = intel_flash_attn_forward(q, k, v, causal=True)
        loss_minus = (out_minus * grad_output).sum().item()
        
        # Restore original value
        q.data[b, h, s, d_idx] = q_orig
        
        # Numerical gradient
        num_grad = (loss_plus - loss_minus) / (2 * epsilon)
        
        # Analytical gradient
        ana_grad = q.grad[b, h, s, d_idx].item()
        
        # Compare
        rel_error = abs(num_grad - ana_grad) / (abs(num_grad) + abs(ana_grad) + 1e-8)
        
        if rel_error < 0.01:  # 1% relative error tolerance
            status = "✅"
        else:
            status = "❌"
            
        print(f"{status} Position ({h},{s},{d_idx}): numerical={num_grad:.6f}, "
              f"analytical={ana_grad:.6f}, rel_error={rel_error:.4f}")
    
    print("\n✅ Gradient correctness test completed")
    return True


def main():
    """Run all validation tests"""
    print("🔍 Flash Attention Enhanced Validation Test Suite")
    print("="*80)
    
    # Check environment
    if INTEL_GPU_AVAILABLE:
        print(f"✅ Intel GPU detected: {torch.xpu.device_count()} device(s)")
    elif torch.cuda.is_available():
        print(f"✅ CUDA GPU detected: {torch.cuda.device_count()} device(s)")
    else:
        print("⚠️  No GPU detected, using CPU")
    
    # Initialize distributed if running with MPI
    if 'OMPI_COMM_WORLD_SIZE' in os.environ or 'PMI_SIZE' in os.environ:
        from sp_aurora.mpi_utils import setup_mpi_distributed
        setup_mpi_distributed()
    
    # Run tests
    tests = [
        ("Numerical Precision", test_numerical_precision),
        ("Memory Efficiency", test_memory_efficiency),
        ("Gradient Correctness", test_gradient_correctness),
        ("Ring Communication Pattern", test_ring_communication_pattern),
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"\n❌ Test '{test_name}' crashed: {e}")
            traceback.print_exc()
            results.append((test_name, False))
    
    # Summary
    print("\n" + "="*80)
    print("📊 VALIDATION SUMMARY")
    print("="*80)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "✅ PASSED" if result else "❌ FAILED"
        print(f"{test_name}: {status}")
    
    print(f"\nTotal: {passed}/{total} tests passed")
    
    if passed == total:
        print("\n🎉 All validation tests passed!")
        return 0
    else:
        print(f"\n⚠️  {total - passed} test(s) failed.")
        return 1


if __name__ == "__main__":
    sys.exit(main())